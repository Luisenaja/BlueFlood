{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  .container { width:99% !important; } \n",
       "  div.cell{\n",
       "    width:100%;\n",
       "    margin-left:1%;\n",
       "    margin-right:auto;\n",
       "  }\n",
       "  div.output_area {\n",
       "   display: -webkit-box;\n",
       "   padding: 13px;\n",
       "  }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## Jupyter and Ipython config and tweaks\n",
    "# import ipy_autoreload\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "###### fix notebook theme: make cells wide and add a margin to output cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "  .container { width:99% !important; } \n",
    "  div.cell{\n",
    "    width:100%;\n",
    "    margin-left:1%;\n",
    "    margin-right:auto;\n",
    "  }\n",
    "  div.output_area {\n",
    "   display: -webkit-box;\n",
    "   padding: 13px;\n",
    "  }\n",
    "</style>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Import libraries and define helper functions\n",
    "#################################\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import sys, traceback\n",
    "import gc\n",
    "import numpy as np\n",
    "#to dump objects\n",
    "import cPickle as pickle\n",
    "import operator\n",
    "import itertools\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('PDF')\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "fm = mpl.font_manager\n",
    "fm.get_cachedir()\n",
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('font',**{'family':'serif','serif':['Times']})\n",
    "rc('text', usetex=True)\n",
    "import pylab\n",
    "from numpy.core.function_base import linspace\n",
    "from numpy.lib.function_base import meshgrid\n",
    "from numpy.core.numeric import array\n",
    "from matplotlib import colors\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "#from mpl_toolkits import mplot3d\n",
    "from matplotlib.collections import LineCollection, PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "\n",
    "from matplotlib import cm\n",
    "from collections import OrderedDict, Set\n",
    "\n",
    "import json, urllib\n",
    "import copy\n",
    "import msgpack\n",
    "# import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################# Constants and Functions \n",
    "######################################################\n",
    "#constants\n",
    "experiment_time_stamp_idx=0\n",
    "ble_mode_idx=1\n",
    "tx_power_idx=2\n",
    "tx_offset_idx=3\n",
    "capture_idx=4\n",
    "prr_1_idx=5\n",
    "prr_2_idx=6\n",
    "prr_ct_idx=7\n",
    "rssi_avg_idx=8\n",
    "rssi_stddev_idx=9\n",
    "ts_delta_avg_idx=10\n",
    "ts_delta_stddev_idx=11\n",
    "\n",
    "class expdesc_usage_class:\n",
    "  ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed = range(0,11)\n",
    "\n",
    "class expsummary_usage_class:\n",
    "  avg_per, stddev_per, avg_hopcount, stddev_hopcount, avg_onslots, stddev_onslots = range(0,6)\n",
    "\n",
    "expdesc_usage = expdesc_usage_class()\n",
    "expsummary_usage = expsummary_usage_class()\n",
    "#constatnts\n",
    "Ble_1Mbit=3 #/*!< 1 Mbit/s Bluetooth Low Energy */\n",
    "Ble_2Mbit=4 #/*!< 2 Mbit/s Bluetooth Low Energy */\n",
    "Ble_LR125Kbit=5 #/*!< Long range 125 kbit/s (TX Only - RX supports both) */\n",
    "Ble_LR500Kbit=6 #/*!< Long range 500 kbit/s (TX Only - RX supports both) */\n",
    "IEER802154_250Kbit=15\n",
    "ble_mode_str_list = [\"1Mbps\", \"2Mbps\", \"LR-125Kbps\", \"LR-500Kbps\", \"IEEE 802.15.4\"]\n",
    "ble_mode_str_list_compact = [\"1M\", \"2M\", \"125K\", \"500K\", \"15.4\"]\n",
    "blueFloodSlotSizes = {Ble_1Mbit:0.5325, Ble_2Mbit:0.3636, Ble_LR500Kbit:1.324, Ble_LR125Kbit:3.677, IEER802154_250Kbit:1.829}\n",
    "#ble_mode_str_dict = {Ble_1Mbit: \"1Mbps\", Ble_2Mbit:\"2Mbps\", Ble_LR125Kbit:\"LR-125Kbps\", Ble_LR500Kbit:\"LR-500Kbps\"}\n",
    "ble_mode_str_dict = {Ble_1Mbit: \"1 M\", Ble_2Mbit:\"2 M\", Ble_LR125Kbit:\"125 K\", Ble_LR500Kbit:\"500 K\", IEER802154_250Kbit:\"15.4\"}\n",
    "\n",
    "#String format print experiment name from experiment description dictionary\n",
    "expname_fmt = \"{}: {}_{}_{}_{}_{}_{} ble_mode_{}_txpower_{}_txoffset_{}_capt_{}_packet_size_{}_nch_{}_och_{}_ntx_{}_i_{}_testbed_{}\"\n",
    "\n",
    "def exp_desc_to_string(exp, expdesc):\n",
    "  pp=[exp]+expdesc[exp][expdesc_usage.ts]+expdesc[exp][1:]\n",
    "  return expname_fmt.format(*pp)\n",
    "\n",
    "def ble_mode_str(m):\n",
    "  return ble_mode_str_list[m-3] if (m>=3 or m<=6) else (\"RF Mode Unknown %d\" %(m))\n",
    "\n",
    "def ble_mode_str_compact(m):\n",
    "  return ble_mode_str_list_compact[m-3] if (m>=3 or m<=6) else (\"RF Mode Unknown %d\" %(m))\n",
    "\n",
    "##unused\n",
    "# plot_ts_delta_over = False\n",
    "# plot_rssi_diff_over = False\n",
    "\n",
    "linestylesDict = OrderedDict(\n",
    "    [('solid',               (0, ())),\n",
    "     ('loosely dotted',      (0, (1, 10))),\n",
    "     ('dotted',              (0, (1, 5))),\n",
    "     ('densely dotted',      (0, (1, 1))),\n",
    "\n",
    "     ('loosely dashed',      (0, (5, 10))),\n",
    "     ('dashed',              (0, (5, 5))),\n",
    "     ('densely dashed',      (0, (5, 1))),\n",
    "\n",
    "     ('loosely dashdotted',  (0, (3, 10, 1, 10))),\n",
    "     ('dashdotted',          (0, (3, 5, 1, 5))),\n",
    "     ('densely dashdotted',  (0, (3, 1, 1, 1))),\n",
    "\n",
    "     ('loosely dashdotdotted', (0, (3, 10, 1, 10, 1, 10))),\n",
    "     ('dashdotdotted',         (0, (3, 5, 1, 5, 1, 5))),\n",
    "     ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1)))])\n",
    "#linestyles = linestylesDict.items()\n",
    "linestyles = ['-', '--', '-.', ':',linestylesDict['densely dotted']]\n",
    "markers = ['o', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'v', '^', '<', '>',]\n",
    "\n",
    "def timing(f):\n",
    "  def wrap(*args, **kwargs):\n",
    "    time1 = time.time()\n",
    "    ret = f(*args, **kwargs)\n",
    "    time2 = time.time()\n",
    "    print '%s function took %f ms' % (f.func_name, (time2-time1)*1000.0)\n",
    "    return ret\n",
    "  return wrap\n",
    "\n",
    "@timing\n",
    "def saveObject(userobj, filename):\n",
    "  with open(filename, 'wb') as outputFile:\n",
    "    gc.disable()\n",
    "    pickle.dump(userobj, outputFile, pickle.HIGHEST_PROTOCOL)\n",
    "    gc.enable()\n",
    "\n",
    "@timing\n",
    "def loadObject(filename):\n",
    "  userobj = None\n",
    "  with open(filename, 'rb') as inputFile:\n",
    "    gc.disable()\n",
    "    userobj = pickle.load(inputFile)\n",
    "    gc.enable()\n",
    "  return userobj\n",
    "\n",
    "@timing\n",
    "def saveObjectMP(userobj, filename):\n",
    "  with open(filename, 'wb') as outputFile:\n",
    "    gc.disable()\n",
    "    msgpack.pack(userobj, outputFile)\n",
    "    gc.enable()\n",
    "\n",
    "@timing\n",
    "def loadObjectMP(filename):\n",
    "  userobj = None\n",
    "  with open(filename, 'rb') as inputFile:\n",
    "    gc.disable()\n",
    "    userobj = msgpack.unpack(inputFile)\n",
    "    gc.enable()\n",
    "  return userobj\n",
    "\n",
    "def tx_status_map_bad_rx(t):\n",
    "  ''' \n",
    "  '-': rx ok\n",
    "  '1': mote 1 tx\n",
    "  '2': mote 2 tx\n",
    "  'B': both tx\n",
    "  ':': skipped slot\n",
    "  ''' \n",
    "  if(t in ['-', '1', '2', 'B', ':', 'X', '\\0']):\n",
    "    return 0\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "def tx_status_map_tx(t):\n",
    "  ''' \n",
    "  '-': rx ok\n",
    "  '1': mote 1 tx\n",
    "  '2': mote 2 tx\n",
    "  'B': both tx\n",
    "  ':': skipped slot\n",
    "  ''' \n",
    "  if(t in ['1', '2', 'B', 'X']):\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "def tx_status_map_tx2(t):\n",
    "  ''' \n",
    "  '-': rx ok\n",
    "  '1': mote 1 tx\n",
    "  '2': mote 2 tx\n",
    "  'B': both tx\n",
    "  ':': skipped slot\n",
    "  ''' \n",
    "  if(t in ['-', ':']):\n",
    "    return 0\n",
    "  elif(t in ['1', '2', 'B', 'X']):  \n",
    "    return 1\n",
    "  else:\n",
    "    return 2\n",
    "  \n",
    "#### Functions to parse experiment logs, for Graz testbed\n",
    "##############\n",
    "#12345_2019_12_18_18_05_59_dirty-channel__ble_mode_6_txpower_4_txoffset_0_capture_0_packet_size_38_nch_3_och_0_ntx_4_i_0_testbed_GRAZ_TESTBED None\n",
    "expname_regex = re.compile(\"(\\d+)_(\\d+)_(\\d+)_(\\d+)_(\\d+)_(\\d+)_(\\d+)(?:_dirty-channel)?_?_ble_mode_(\\d+)_txpower_(-?\\d+)_txoffset_(-?\\d+)_capture_(\\d)(_packet_size_(\\d+))?(_nch_(\\d+))?(_och_(\\d+))?(_ntx_(\\d+))?(_i_(\\d+))?(_testbed_(\\w+)_TESTBED)?\")\n",
    "def parse_experiment_name(expname, nch=1, och=1, ntx=4, packet_size = 38):\n",
    "  res = expname_regex.match(expname)\n",
    "  #print dirname\n",
    "  parsed = None\n",
    "  if res:\n",
    "    exp_number = int(res.group(1))\n",
    "    ts = [int(res.group(2)), int(res.group(3)), int(res.group(4)), int(res.group(5)), int(res.group(6)),int(res.group(7))]\n",
    "    ble_mode = int(res.group(8))\n",
    "    txpower = int(res.group(9))\n",
    "    txoffset = int(res.group(10))\n",
    "    capture = int(res.group(11))\n",
    "    initiator = None\n",
    "    testbed = None\n",
    "    if res.group(12):\n",
    "        if str(res.group(12)).startswith(\"_packet_size_\"):\n",
    "            packet_size = int(res.group(13))\n",
    "    if res.group(14):\n",
    "        if str(res.group(14)).startswith(\"_nch_\"):\n",
    "            nch = int(res.group(15))\n",
    "    if res.group(16):\n",
    "        if str(res.group(16)).startswith(\"_och_\"):\n",
    "            och = int(res.group(17))\n",
    "    if res.group(18):\n",
    "        if str(res.group(18)).startswith(\"_ntx_\"):\n",
    "            ntx = int(res.group(19))\n",
    "    if res.group(20):\n",
    "        if str(res.group(20)).startswith(\"_i_\"):\n",
    "            initiator = int(res.group(21))       \n",
    "    if res.group(22):\n",
    "        if str(res.group(22)).startswith(\"_testbed_\"):\n",
    "            testbed = str(res.group(23))   \n",
    "    parsed = [exp_number, ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed]\n",
    "  return parsed\n",
    "\n",
    "#2019-12-19 00:32:53.102248|{tx-49} :B---AAAAAAAAAA...\n",
    "#1574953250505373 {tx-111} :BCB-CAAAAA....\n",
    "line_tx_regex = re.compile(\"(.*)[\\s\\|]\\{tx-(\\d+)\\}\\s(.*)\")\n",
    "def parse_tx_experiment_line(line):\n",
    "  #93_2018_08_20_13_12_56_ble_mode_3_txpower_-20_txoffset_0_capture_0\n",
    "  res = line_tx_regex.match(line)\n",
    "  parsed = None\n",
    "  if res:\n",
    "    tsstr = str(res.group(1))\n",
    "    rd = int(res.group(2))\n",
    "    lline = str(res.group(3))\n",
    "    parsed = tsstr, rd, lline\n",
    "  return parsed\n",
    "\n",
    "def process_tx_status(lline):\n",
    "  lline=str(lline)\n",
    "  is_initiator=False; synced=-1; sync_slot=-1; tot=0\n",
    "  if len(lline) > 1: #and len(lline) <= Round.ROUND_LEN+1:\n",
    "#                 if(len(lline)<Round.ROUND_LEN):\n",
    "#                     lline = lline.rjust(Round.ROUND_LEN+ 1, \"A\")\n",
    "#                     lline=lline.replace(':','A') #replace \n",
    "    ch=lline[1]\n",
    "    #replace left dots with the letter, and remove the right dots!\n",
    "    lline=re.sub(r'\\.*$',r'',lline) #remove trailing dots\n",
    "    lline=lline.replace('.',ch) #replace left dots with the first letter\n",
    "    tx_status = lline[1:]  #remove \":\"                  \n",
    "    #print self.tx_status\n",
    "    is_initiator, sync_slot, tot = [False, -1, 0]\n",
    "    if len(tx_status) > 0:\n",
    "      synced = tx_status.find(\"-\") \n",
    "      sync_slot = 1 + synced if synced != -1 else -1  #first rx ok\n",
    "      is_initiator = tx_status[0] in ['B', '1', '2']\n",
    "      if is_initiator:\n",
    "        sync_slot = 0\n",
    "\n",
    "      tot=len(tx_status)\n",
    "    \n",
    "  return is_initiator, sync_slot, tot \n",
    "\n",
    "\n",
    "###############\n",
    "testbeds={\"GRAZ\", \"CAU\", \"HOME\"}\n",
    "def load_testbed_node_log_files(dirname, testbed=\"GRAZ\"):\n",
    "  #experiment_parameters\n",
    "  dn = os.path.basename(os.path.normpath(dirname))\n",
    "  if(testbed == \"GRAZ\"):\n",
    "    exp_number = int(dn.split(\"_\")[1])\n",
    "    logfilename_regex = re.compile(\"log_(\\d+)\\.txt\")\n",
    "  else:\n",
    "    exp_number = int(dn.split(\"_\")[0])\n",
    "    logfilename_regex = re.compile(\"raspi(\\d+)\")\n",
    "    dirname = os.path.join(dirname, \"logs\")\n",
    "  files=os.listdir(dirname)\n",
    "  files.sort()\n",
    "  nodes = dict()\n",
    "  for nodefile in files:    \n",
    "    fpath = os.path.join(dirname, nodefile)\n",
    "    if(testbed == \"GRAZ\"):\n",
    "      if not os.path.isfile(fpath):\n",
    "        continue\n",
    "    else:\n",
    "      fpath = os.path.join(fpath, \"log.txt\")\n",
    "      if not os.path.isfile(fpath):\n",
    "        continue\n",
    "        ##parse node number\n",
    "    res = logfilename_regex.match(str(nodefile))\n",
    "    if res is None:\n",
    "      continue\n",
    "    node_id=int(res.group(1))\n",
    "#       print node_id\n",
    "    #node_id=-1\n",
    "    node_dict = dict()\n",
    "    node_dict_is_initiator = dict()\n",
    "    node_dict_sync_slot = dict()\n",
    "    node_dict_tot_slot = dict()\n",
    "    node_list_failed_rounds = list()\n",
    "\n",
    "    ##parse tx status line\n",
    "    for lline in open(fpath, 'r').readlines():\n",
    "      if lline is None:\n",
    "        continue\n",
    "      lline=lline.strip()\n",
    "      parsed = parse_tx_experiment_line(lline)\n",
    "      if parsed is None:\n",
    "        continue\n",
    "      tsstr, rd, lline = parsed\n",
    "      is_initiator, sync_slot, tot = process_tx_status(lline)\n",
    "      if tot == 0: #corrupted tx log line\n",
    "        continue\n",
    "      node_dict[rd] = [is_initiator, sync_slot, tot]\n",
    "      node_dict_is_initiator[rd] = is_initiator\n",
    "      if sync_slot > -1: #recieved correctly\n",
    "        node_dict_sync_slot[rd] = sync_slot\n",
    "      elif not is_initiator:\n",
    "        node_list_failed_rounds.append(rd)\n",
    "      node_dict_tot_slot[rd] = tot\n",
    "    \n",
    "    nodes[node_id] = dict()\n",
    "    nodes[node_id][\"all\"] = node_dict.copy() #shallow copy / reference pointer\n",
    "    nodes[node_id][\"sync\"] = node_dict_sync_slot.copy() #shallow copy / reference pointer\n",
    "    nodes[node_id][\"is_initiator\"] = node_dict_is_initiator.copy()\n",
    "    nodes[node_id][\"tot\"] = node_dict_tot_slot.copy()\n",
    "    nodes[node_id][\"failed_rounds\"] = node_list_failed_rounds\n",
    "    syncedrounds = node_dict_sync_slot.keys()\n",
    "    initiator_rounds = np.sum(node_dict_is_initiator.values())\n",
    "    syncslots = [ s for s in node_dict_sync_slot.values() if s > 0]\n",
    "    totslots = [ node_dict_tot_slot[i] for i in node_dict_tot_slot.keys() if not node_dict_is_initiator[i] ]\n",
    "    if len(syncslots) > 0:\n",
    "#       number_of_rounds = len(syncslots)\n",
    "      nodes[node_id][\"hopcount\"] =  [ min(syncslots), max(syncslots), np.average(syncslots), np.std(syncslots) ]\n",
    "      nodes[node_id][\"totslots\"] =  [ min(totslots), max(totslots), np.average(totslots), np.std(totslots) ]\n",
    "    else:\n",
    "#       number_of_rounds = initiator_rounds\n",
    "      nodes[node_id][\"hopcount\"] =  [ 0, 0, 0, 0 ]\n",
    "      nodes[node_id][\"totslots\"] =  [ 0, 0, 0, 0 ]\n",
    "    \n",
    "    number_of_failed_rounds = len(node_list_failed_rounds)\n",
    "    #Fix PER: it was overestimated by doing the ratio of failed rounds to sync rounds, which was wrong.\n",
    "    number_of_rounds = len(syncslots) + number_of_failed_rounds\n",
    "    number_of_logged_rounds = len(nodes[node_id][\"is_initiator\"])\n",
    "    initiator_node = ( number_of_rounds == 0 ) and ( number_of_logged_rounds > 0 ) and ( number_of_logged_rounds == len(nodes[node_id][\"sync\"]) )\n",
    "\n",
    "#     initiator_node = ( number_of_failed_rounds == 0 ) and ( len(node_dict_is_initiator) == len(node_dict_sync_slot) )\n",
    "    if initiator_node:\n",
    "      nodes[node_id][\"hopcount\"] =  [ 0, 0, -1, 0 ]\n",
    "      nodes[node_id][\"totslots\"] =  [ 0, 0, -1, 0 ]\n",
    "      nodes[node_id][\"PER\"] = -1\n",
    "    elif number_of_rounds == 0:\n",
    "      nodes[node_id][\"PER\"] = 1\n",
    "    else :\n",
    "      nodes[node_id][\"PER\"] = 1.0*number_of_failed_rounds / number_of_rounds\n",
    "      \n",
    "  return nodes\n",
    "\n",
    "def download_grazq(graz_qfile, graz_secretfile):\n",
    "  with open(graz_secretfile, \"r\") as GRAZ_APIKEY:\n",
    "    key=GRAZ_APIKEY.read()\n",
    "    grazqurl=\"https://iti-testbed.tugraz.at/api/queue?key=%s\" % (key)\n",
    "    response = urllib.urlopen(grazqurl)\n",
    "    with open(graz_qfile, \"w\") as graz_qfilef:\n",
    "      graz_qfilef.write(response.read())\n",
    "\n",
    "def load_grazq(graz_qfile):\n",
    "  #grazq = json.loads(response.read())\n",
    "  with open(graz_qfile, \"r\") as graz_qfilef:\n",
    "    grazq = json.loads(graz_qfilef.read())\n",
    "    return grazq\n",
    "\n",
    "def load_grazq_online(graz_secretfile):\n",
    "  with open(graz_secretfile, \"r\") as GRAZ_APIKEY:\n",
    "    key=GRAZ_APIKEY.read()\n",
    "    grazqurl=\"https://iti-testbed.tugraz.at/api/queue?key=%s\" % (key)\n",
    "    response = urllib.urlopen(grazqurl)\n",
    "    grazq = json.loads(response.read())\n",
    "    return grazq\n",
    "\n",
    "###Load and process exp log files\n",
    "### Parse experiments and save results\n",
    "def load_logs_process_save_graz( wdirg, grazq, maxjobid, minjobid=0 ):\n",
    "  expdict = dict()\n",
    "  expdesc = dict()\n",
    "  for job in grazq:\n",
    "    exp_number=int(job[\"id\"])\n",
    "    if not (exp_number <= maxjobid and exp_number >= minjobid):\n",
    "      continue\n",
    "    n=\"%s_%s\"% (job[\"id\"], job[\"name\"])\n",
    "    parsed_exp=parse_experiment_name(n)\n",
    "    if parsed_exp is not None:\n",
    "      #print n, parse_experiment_name(n)\n",
    "      [exp_number, ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed] = parsed_exp\n",
    "      exp_path = os.path.join(wdirg, \"logs_%s\" % (job[\"id\"]))\n",
    "      try:\n",
    "        print n\n",
    "        nodes = load_testbed_node_log_files(exp_path, \"GRAZ\")\n",
    "        expdict[exp_number] = nodes.copy()\n",
    "        expdesc[exp_number] = [ ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed]\n",
    "        saveObject(nodes, os.path.join(exp_path, \"nodes.pickle\"))  \n",
    "      except Exception as e:\n",
    "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "        print repr(traceback.format_exception(exc_type, exc_value, exc_traceback))\n",
    "\n",
    "###Load and process exp log files\n",
    "### Parse experiments and save results\n",
    "def load_logs_process_save( wdirg, maxjobid, minjobid=0 ):\n",
    "  jobs_dirs=os.listdir(wdirg)\n",
    "  jobs_dirs.sort()\n",
    "  #print jobs_dirs\n",
    "  expdict = dict()\n",
    "  expdesc = dict()\n",
    "  for jobd in jobs_dirs:\n",
    "    exp_path = os.path.join(wdirg, jobd)\n",
    "    if os.path.isdir(exp_path):\n",
    "      parsed_exp=parse_experiment_name(jobd)\n",
    "      print jobd, parsed_exp\n",
    "      if parsed_exp is not None:\n",
    "        [exp_number, ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed] = parsed_exp\n",
    "        if not (exp_number <= maxjobid and exp_number >= minjobid):\n",
    "          continue\n",
    "        try:\n",
    "          print \"Parsing %s Testbed exp %d\" % ( testbed, exp_number )\n",
    "          nodes = load_testbed_node_log_files(exp_path, testbed)\n",
    "          expdict[exp_number] = nodes.copy()\n",
    "          expdesc[exp_number] = [ ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed]\n",
    "          saveObject(nodes, os.path.join(exp_path, \"nodes.pickle\"))  \n",
    "        except Exception as e:\n",
    "          exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "          print repr(traceback.format_exception(exc_type, exc_value, exc_traceback))\n",
    "  return expdict, expdesc\n",
    "          \n",
    "def load_processed_logs_pickle_graz( wdirg, grazq, maxjobid, minjobid=0 ):\n",
    "  expdict = dict()\n",
    "  expdesc = dict()\n",
    "  for job in grazq:\n",
    "    exp_number=int(job[\"id\"])\n",
    "    if not (exp_number <= maxjobid and exp_number >= minjobid):\n",
    "      continue\n",
    "    n=\"%s_%s\"% (job[\"id\"], job[\"name\"])\n",
    "    parsed_exp=parse_experiment_name(n)\n",
    "    if parsed_exp is not None:\n",
    "      #print n, parse_experiment_name(n)\n",
    "      exp_path = os.path.join(wdirg, \"logs_%s\" % (job[\"id\"]))\n",
    "      [exp_number, ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed] = parsed_exp\n",
    "      try:\n",
    "        print \"Loading %s Testbed exp %d\" % ( testbed, exp_number )\n",
    "        expdict[exp_number] = loadObject(os.path.join(exp_path, \"nodes.pickle\"))  \n",
    "        expdesc[exp_number] = [ ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed]\n",
    "      except Exception as e:\n",
    "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "        print repr(traceback.format_exception(exc_type, exc_value, exc_traceback))\n",
    "  return expdict, expdesc\n",
    "\n",
    "def load_processed_logs_pickle( wdirg, maxjobid, minjobid=0 ):\n",
    "  expdict = dict()\n",
    "  expdesc = dict()\n",
    "  jobs_dirs=os.listdir(wdirg)\n",
    "  jobs_dirs.sort()\n",
    "  for jobd in jobs_dirs:\n",
    "    exp_path = os.path.join(wdirg, jobd)\n",
    "    if os.path.isdir(exp_path):\n",
    "      parsed_exp=parse_experiment_name(jobd)\n",
    "      if parsed_exp is not None:\n",
    "        [exp_number, ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed] = parsed_exp\n",
    "        if not (exp_number <= maxjobid and exp_number >= minjobid):\n",
    "          continue\n",
    "        try:\n",
    "          print \"Loading %s Testbed exp %d\" % ( testbed, exp_number )\n",
    "          expdict[exp_number] = loadObject(os.path.join(exp_path, \"nodes.pickle\"))  \n",
    "          expdesc[exp_number] = [ ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed]\n",
    "        except Exception as e:\n",
    "          exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "          print repr(traceback.format_exception(exc_type, exc_value, exc_traceback))\n",
    "  return expdict, expdesc\n",
    "\n",
    "def make_sorted_array_according_to_indices(a, idx):\n",
    "  a = np.asarray(a)\n",
    "  return a[idx]\n",
    "\n",
    "def sort_summary_array_according_to_x(txpowerdata, blemodes):\n",
    "    #sort according to x\n",
    "    for b in blemodes:\n",
    "      idx = np.argsort(txpowerdata[b][\"x\"])\n",
    "      txpowerdata[b][\"x\"].sort()\n",
    "      txpowerdata[b][\"per1\"] = make_sorted_array_according_to_indices(txpowerdata[b][\"per1\"], idx)\n",
    "      txpowerdata[b][\"perlen\"] = make_sorted_array_according_to_indices(txpowerdata[b][\"perlen\"], idx)\n",
    "      txpowerdata[b][\"perstd1\"] = make_sorted_array_according_to_indices(txpowerdata[b][\"perstd1\"], idx)\n",
    "      txpowerdata[b][\"hopcount1\"] = make_sorted_array_according_to_indices(txpowerdata[b][\"hopcount1\"], idx)\n",
    "      txpowerdata[b][\"hopcountstd1\"] = make_sorted_array_according_to_indices(txpowerdata[b][\"hopcountstd1\"], idx)\n",
    "      txpowerdata[b][\"hopcountlen\"] = make_sorted_array_according_to_indices(txpowerdata[b][\"hopcountlen\"], idx)\n",
    "      txpowerdata[b][\"onslotslen\"] = make_sorted_array_according_to_indices(txpowerdata[b][\"onslotslen\"], idx)\n",
    "      txpowerdata[b][\"onslots1\"] = make_sorted_array_according_to_indices(txpowerdata[b][\"onslots1\"], idx)\n",
    "      txpowerdata[b][\"onslotsstd1\"] = make_sorted_array_according_to_indices(txpowerdata[b][\"onslotsstd1\"], idx)\n",
    "    return txpowerdata\n",
    "  \n",
    "def update_average_stddev(newdata, newstd, newlen, data, datalen, datastd):\n",
    "  p=data * datalen + newdata * newlen\n",
    "  pl=datalen + newlen\n",
    "  pe=datastd * datalen + newstd * newlen\n",
    "  updated_data_average = p / pl\n",
    "  updated_std = pe / pl\n",
    "  updated_len = pl\n",
    "  return updated_data_average, updated_std, updated_len\n",
    "\n",
    "#########################\n",
    "\n",
    "def extract_exp_summary_parameterized(expdesc, expdict, startexp, blemodes, parameters, index):\n",
    "  #parameters.insert(0,0) # insert fake ts at index 0\n",
    "  parameters[index]=0 #make sure the parameter we plot against is zero here\n",
    "  parameters[expdesc_usage.ble_mode]=0\n",
    "#   [ ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0, testbed0 ] = parameters\n",
    "  expsummary=dict()\n",
    "  txpowerdata = dict()\n",
    "  for b in blemodes:\n",
    "    txpowerdata[b] = dict()\n",
    "    txpowerdata[b][\"x\"] = list()\n",
    "    txpowerdata[b][\"per1\"] = list() #per experiment avg\n",
    "    txpowerdata[b][\"per\"] = list() #avg of all experiments\n",
    "    txpowerdata[b][\"perlen\"] = list()\n",
    "    txpowerdata[b][\"perstd1\"] = list() #per experiment nodes stddev\n",
    "    txpowerdata[b][\"perstd\"] = list() #stddev of all experiments averages\n",
    "    txpowerdata[b][\"hopcount1\"] = list()\n",
    "    txpowerdata[b][\"hopcount\"] = list()\n",
    "    txpowerdata[b][\"hopcountlen\"] = list()\n",
    "    txpowerdata[b][\"hopcountstd\"] = list()  \n",
    "    txpowerdata[b][\"hopcountstd1\"] = list()  \n",
    "    txpowerdata[b][\"onslots1\"] = list()\n",
    "    txpowerdata[b][\"onslots\"] = list()\n",
    "    txpowerdata[b][\"onslotslen\"] = list()\n",
    "    txpowerdata[b][\"onslotsstd\"] = list()\n",
    "    txpowerdata[b][\"onslotsstd1\"] = list()\n",
    "  for expid in expdesc.keys():\n",
    "    if expid >= startexp:\n",
    "      #[ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed] = expdesc[expid]\n",
    "      thisexpdesc = copy.deepcopy(expdesc[expid])\n",
    "      #remove ts, and the x-axis parameter that we plot against:\n",
    "      thisexpdesc[0]=0\n",
    "      thisexpdesc[index]=0\n",
    "      ble_mode=expdesc[expid][expdesc_usage.ble_mode]\n",
    "      thisexpdesc[expdesc_usage.ble_mode]=0\n",
    "\n",
    "      \n",
    "      if thisexpdesc == parameters:\n",
    "        nodes = expdict[expid].copy()\n",
    "        per = [d[\"PER\"] for d in list(nodes.values()) if d[\"PER\"] > -1]\n",
    "        if len(per) == 0:\n",
    "          continue\n",
    "        \n",
    "        hopcounts = [ nodes[node_id][\"hopcount\"][2] for node_id in nodes.keys() if nodes[node_id][\"hopcount\"][2] > 0]\n",
    "        onslots = [ nodes[node_id][\"totslots\"][2] for node_id in nodes.keys() if nodes[node_id][\"totslots\"][2] > 0]\n",
    "        avg_per=np.mean(per)\n",
    "        stddev_per=np.std(per)\n",
    "        avg_onslots = np.mean(onslots)\n",
    "        stddev_onslots = np.std(onslots)\n",
    "        avg_hopcount=np.mean(hopcounts)\n",
    "        stddev_hopcount=np.std(hopcounts)\n",
    "        expsummary[expid] = [avg_per, stddev_per, avg_hopcount, stddev_hopcount, avg_onslots, stddev_onslots ]\n",
    "        param = expdesc[expid][index]\n",
    "        if param not in txpowerdata[ble_mode][\"x\"]:\n",
    "          txpowerdata[ble_mode][\"x\"].append(param)\n",
    "          txpowerdata[ble_mode][\"per1\"].append([])\n",
    "          txpowerdata[ble_mode][\"perlen\"].append([])\n",
    "          txpowerdata[ble_mode][\"perstd1\"].append([])\n",
    "          txpowerdata[ble_mode][\"hopcount1\"].append([])\n",
    "          txpowerdata[ble_mode][\"hopcountstd1\"].append([])\n",
    "          txpowerdata[ble_mode][\"hopcountlen\"].append([])\n",
    "          txpowerdata[ble_mode][\"onslotslen\"].append([])\n",
    "          txpowerdata[ble_mode][\"onslots1\"].append([])\n",
    "          txpowerdata[ble_mode][\"onslotsstd1\"].append([])\n",
    "        # we have an experiment. do geometric mean to average the experiments results\n",
    "        idx = txpowerdata[ble_mode][\"x\"].index(param) ### this seems redundant -- idx == len(txpowerdata[ble_mode][\"x\"])-1, if adding a new x, otherwise it is needed\n",
    "        txpowerdata[ble_mode][\"per1\"][idx].append(avg_per)\n",
    "        txpowerdata[ble_mode][\"perlen\"][idx].append(len(per))\n",
    "        txpowerdata[ble_mode][\"perstd1\"][idx].append(stddev_per)\n",
    "        txpowerdata[ble_mode][\"hopcount1\"][idx].append(avg_hopcount)\n",
    "        txpowerdata[ble_mode][\"hopcountstd1\"][idx].append(stddev_hopcount)\n",
    "        txpowerdata[ble_mode][\"hopcountlen\"][idx].append(len(hopcounts))\n",
    "        txpowerdata[ble_mode][\"onslotslen\"][idx].append(len(onslots))\n",
    "        txpowerdata[ble_mode][\"onslots1\"][idx].append(avg_onslots)\n",
    "        txpowerdata[ble_mode][\"onslotsstd1\"][idx].append(stddev_onslots)\n",
    "\n",
    "  txpowerdata = sort_summary_array_according_to_x(txpowerdata, blemodes)    \n",
    "  # do avg, stddev over all experiments repititions \n",
    "  for b in blemodes:\n",
    "    for idx, param in enumerate(txpowerdata[b][\"x\"]):\n",
    "      txpowerdata[b][\"per\"].append(np.mean(txpowerdata[b][\"per1\"][idx]))\n",
    "      txpowerdata[b][\"hopcount\"].append(np.mean(txpowerdata[b][\"hopcount1\"][idx]))\n",
    "      txpowerdata[b][\"onslots\"].append(np.mean(txpowerdata[b][\"onslots1\"][idx]))\n",
    "      txpowerdata[b][\"perstd\"].append(np.std(txpowerdata[b][\"per1\"][idx]))\n",
    "      txpowerdata[b][\"hopcountstd\"].append(np.std(txpowerdata[b][\"hopcount1\"][idx]))\n",
    "      txpowerdata[b][\"onslotsstd\"].append(np.std(txpowerdata[b][\"onslots1\"][idx]))\n",
    "\n",
    "  return txpowerdata, expsummary\n",
    "\n",
    "def plot_summary_plots(txpowerdata, blemodes, file_name, x_lbl, legend_idx=2, doplots=[1,1,1], legendloc='best'):\n",
    "  capsize=3\n",
    "  markersize=3\n",
    "  linewidth=1.6\n",
    "#   linestyle=linestyles[0]\n",
    "  norm = matplotlib.colors.Normalize(vmin=0, vmax=len(blemodes)+1)\n",
    "  ncols=np.sum(doplots)\n",
    "  if ncols <= 0:\n",
    "    raise ValueError('doplots shall enable at least one plot.')\n",
    "  figsize=(4,3) #width, height\n",
    "  figscale=1.5\n",
    "  fig, axx = plt.subplots( ncols=ncols, sharey=False, sharex=True, figsize=(ncols*figsize[0]/figscale, figsize[1]/figscale) )\n",
    "  if ncols == 1:\n",
    "    subax=[axx] #trick to allow using indexing on the axes and have the same code for both cases (single vs multiple axes)\n",
    "  else:\n",
    "    subax=axx\n",
    "\n",
    "  for counter, ble_mode in enumerate(blemodes):\n",
    "    color=plt.get_cmap('Accent')(norm(counter))\n",
    "    marker=markers[counter]\n",
    "    linestyle=linestyles[counter]\n",
    "    labelsarr=[None, None, None]\n",
    "    if legend_idx is not None:\n",
    "      labelsarr[legend_idx]=ble_mode_str_dict[ble_mode]\n",
    "\n",
    "    if doplots[0]:\n",
    "      subax[0].errorbar(txpowerdata[ble_mode][\"x\"], txpowerdata[ble_mode][\"per\"], yerr=txpowerdata[ble_mode][\"perstd\"], label=labelsarr[0], linestyle=linestyle, color = color, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "    if doplots[1]:\n",
    "      subax[doplots[0]].errorbar(txpowerdata[ble_mode][\"x\"], txpowerdata[ble_mode][\"hopcount\"], yerr=txpowerdata[ble_mode][\"hopcountstd\"], label=labelsarr[1], linestyle=linestyle, color = color, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "    if doplots[2]:\n",
    "      subax[doplots[0]+doplots[1]].errorbar(txpowerdata[ble_mode][\"x\"], txpowerdata[ble_mode][\"onslots\"], yerr=txpowerdata[ble_mode][\"onslotsstd\"], label=labelsarr[2], linestyle=linestyle, color = color, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "  \n",
    "  extract_x = [ txpowerdata[b][\"x\"] for b in blemodes ]\n",
    "  extract_x = list(set(itertools.chain(*extract_x)))\n",
    "#   extract_x.sort()\n",
    "  ylabels=[\"End-to-End PER\", \"Hop Count\", \"Active Slots\"]\n",
    "\n",
    "  for i, ax in enumerate(subax):\n",
    "    ax.grid()\n",
    "#     ax.set_xlim(np.min(np.min(extract_x))-0.5, np.max(np.max(extract_x))+0.5)\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.set_ylim(-0.0000001, ylim[1]*1.1)\n",
    "    ax.set_xticks(extract_x)\n",
    "  #   ax.set_xlabel('TX power [dB]')\n",
    "    ax.set_ylabel(ylabels[i])\n",
    "\n",
    "  if doplots[0]:\n",
    "    subax[0].set_ylim(-0.0000001, 1.1) #for PER\n",
    "    subax[0].set_yscale('symlog', linthreshy=0.0001)\n",
    "  if legend_idx is not None:\n",
    "    #   subax[legend_idx].legend(loc=\"best\",  ncol=2, columnspacing=0.3)\n",
    "    subax[legend_idx].legend(loc=legendloc, borderaxespad=0.1,  ncol=3, columnspacing=0.25, labelspacing=0.25, handlelength=1.3, handletextpad=0.5, markerscale=0.8, frameon=True) #, mode=\"expand\"\n",
    "  \n",
    "  fig.text(0.5, 0.00, x_lbl, ha='center')\n",
    "  fig.tight_layout()\n",
    "#   plt.subplots_adjust(left=0, top=2)\n",
    "  plt.savefig(file_name, bbox_inches='tight', dpi=300)\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Fix overestimated PER:\n",
    "#### note that if you load the aggregated objects expdict_cau and expdict_graz, then you do not need to run the correction, as the results were computed using the fixed processing function\n",
    "\n",
    "fix_old_processed_results_cau = 0\n",
    "fix_old_processed_results_graz = 0\n",
    "if fix_old_processed_results_cau:\n",
    "  for exp in expdict_cau.keys(): #[1640]: \n",
    "    if exp < startexpcau:\n",
    "      continue\n",
    "    for node_id in expdict_cau[exp].keys():\n",
    "      syncslots = [ s for s in expdict_cau[exp][node_id][\"sync\"].values() if s > 0]\n",
    "      totslots = [ expdict_cau[exp][node_id][\"tot\"][i] for i in expdict_cau[exp][node_id][\"tot\"].keys() if not expdict_cau[exp][node_id][\"is_initiator\"][i] ]\n",
    "      if len(syncslots) > 0:\n",
    "        expdict_cau[exp][node_id][\"hopcount\"] =  [ min(syncslots), max(syncslots), np.average(syncslots), np.std(syncslots) ]\n",
    "        expdict_cau[exp][node_id][\"totslots\"] =  [ min(totslots), max(totslots), np.average(totslots), np.std(totslots) ]\n",
    "      else:\n",
    "        expdict_cau[exp][node_id][\"hopcount\"] =  [ 0, 0, 0, 0 ]\n",
    "        expdict_cau[exp][node_id][\"totslots\"] =  [ 0, 0, 0, 0 ]\n",
    "    \n",
    "      number_of_failed_rounds = len(expdict_cau[exp][node_id][\"failed_rounds\"])\n",
    "      #Fix PER: it was overestimated by doing the ratio of failed rounds to sync rounds, which was wrong.\n",
    "      number_of_rounds = len(syncslots) + number_of_failed_rounds\n",
    "      number_of_logged_rounds = len(expdict_cau[exp][node_id][\"is_initiator\"])\n",
    "      static_initiator = ( number_of_rounds == 0 ) and ( number_of_logged_rounds > 0 ) and ( number_of_logged_rounds == len(expdict_cau[exp][node_id][\"sync\"]) )\n",
    "#       initiator_node = (number_of_rounds > 0 or static_initiator) and ( number_of_failed_rounds == 0 ) and ( len(totslots)==0 ) #( len( expdict_cau[exp][node_id][\"is_initiator\"] ) == len( expdict_cau[exp][node_id][\"sync\"] ) )\n",
    "      if static_initiator:\n",
    "        expdict_cau[exp][node_id][\"hopcount\"] =  [ 0, 0, -1, 0 ]\n",
    "        expdict_cau[exp][node_id][\"totslots\"] =  [ 0, 0, -1, 0 ]\n",
    "        expdict_cau[exp][node_id][\"PER\"] = -1\n",
    "      elif number_of_rounds == 0:\n",
    "        expdict_cau[exp][node_id][\"PER\"] = 1\n",
    "      else :\n",
    "        expdict_cau[exp][node_id][\"PER\"] = 1.0*number_of_failed_rounds / number_of_rounds\n",
    "      if static_initiator or expdict_cau[exp][node_id][\"PER\"] > 0.9:\n",
    "        print exp, node_id, number_of_rounds, number_of_failed_rounds, len(totslots), len(expdict_cau[exp][node_id][\"sync\"]), number_of_logged_rounds,expdict_cau[exp][node_id][\"PER\"]\n",
    "\n",
    "if fix_old_processed_results_graz:\n",
    "  for exp in expdict_graz.keys():\n",
    "    for node_id in expdict_graz[exp].keys():\n",
    "      syncslots = [ s for s in expdict_graz[exp][node_id][\"sync\"].values() if s > 0]\n",
    "      totslots = [ expdict_graz[exp][node_id][\"tot\"][i] for i in expdict_graz[exp][node_id][\"tot\"].keys() if not expdict_graz[exp][node_id][\"is_initiator\"][i] ]\n",
    "      if len(syncslots) > 0:\n",
    "        expdict_graz[exp][node_id][\"hopcount\"] =  [ min(syncslots), max(syncslots), np.average(syncslots), np.std(syncslots) ]\n",
    "        expdict_graz[exp][node_id][\"totslots\"] =  [ min(totslots), max(totslots), np.average(totslots), np.std(totslots) ]\n",
    "      else:\n",
    "        expdict_graz[exp][node_id][\"hopcount\"] =  [ 0, 0, 0, 0 ]\n",
    "        expdict_graz[exp][node_id][\"totslots\"] =  [ 0, 0, 0, 0 ]\n",
    "      \n",
    "      number_of_failed_rounds = len(expdict_graz[exp][node_id][\"failed_rounds\"])\n",
    "      #Fix PER: it was overestimated by doing the ratio of failed rounds to sync rounds, which was wrong.\n",
    "      number_of_rounds = len(syncslots) + number_of_failed_rounds\n",
    "      number_of_logged_rounds = len(expdict_graz[exp][node_id][\"is_initiator\"])\n",
    "      static_initiator = ( number_of_rounds == 0 ) and ( number_of_logged_rounds > 0 ) and ( number_of_logged_rounds == len(expdict_graz[exp][node_id][\"sync\"]) )\n",
    "      if static_initiator:\n",
    "        expdict_graz[exp][node_id][\"hopcount\"] =  [ 0, 0, -1, 0 ]\n",
    "        expdict_graz[exp][node_id][\"totslots\"] =  [ 0, 0, -1, 0 ]\n",
    "        expdict_graz[exp][node_id][\"PER\"] = -1\n",
    "      elif number_of_rounds == 0:\n",
    "        expdict_graz[exp][node_id][\"PER\"] = 1\n",
    "      else :\n",
    "        expdict_graz[exp][node_id][\"PER\"] = 1.0*number_of_failed_rounds / number_of_rounds\n",
    "      if static_initiator or expdict_graz[exp][node_id][\"PER\"] > 0.9:\n",
    "        print exp, node_id, number_of_rounds, number_of_failed_rounds, len(totslots), len(expdict_graz[exp][node_id][\"sync\"]), number_of_logged_rounds, expdict_graz[exp][node_id][\"PER\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graz_secretfile=\"/Users/beshr/work/blueflood/examples/nrf-glossy/graz_apifile.secret\"\n",
    "# graz_qfile=\"/Users/beshr/work/blueflood/examples/nrf-glossy/graz_qfile.json\"\n",
    "# grazq = load_grazq_online(graz_secretfile)\n",
    "# download_grazq(graz_qfile, graz_secretfile)\n",
    "# grazq = load_grazq(graz_qfile)\n",
    "wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/graz_testbed\"\n",
    "minjobid_graz=32155\n",
    "maxjobid_graz=32227\n",
    "# expdict_graz2, expdesc_graz2 = load_logs_process_save_graz( wdirg, grazq, maxjobid_graz, minjobid_graz )\n",
    "## Load results dictionary\n",
    "## expdict_graz, expdesc_graz = load_processed_logs_pickle_graz( wdirg, grazq, maxjobid_graz, minjobid_graz )\n",
    "### load new results update working dictionary\n",
    "# minjobid_graz=0\n",
    "# maxjobid_graz=24000\n",
    "## expdict_graz2, expdesc_graz2 = load_processed_logs_pickle_graz( wdirg, grazq, maxjobid_graz, minjobid_graz )\n",
    "# expdict_graz.update(expdict_graz2)\n",
    "# expdesc_graz.update(expdesc_graz2)\n",
    "## print list of loaded experiments\n",
    "# grazenums = list(expdesc_graz.keys())\n",
    "# grazenums.sort()\n",
    "# print grazenums\n",
    "# del expdict_graz[27473], expdesc_graz[27473]\n",
    "# del expdict_graz[32058], expdesc_graz[32058]\n",
    "# del expdict_graz[32060], expdesc_graz[32060]\n",
    "\n",
    "# wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/home_testbed\"\n",
    "# maxjobid_home=23250\n",
    "# load_logs_process_save( wdirg, maxjobid_home )\n",
    "# expdict_home, expdesc_home = load_processed_logs_pickle( wdirg, maxjobid_home )\n",
    "\n",
    "wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/cau_testbed\"\n",
    "minjobid_cau=1661\n",
    "maxjobid_cau=1724\n",
    "# expdict_cau2, expdesc_cau2 = load_logs_process_save( wdirg, maxjobid_cau, minjobid_cau )\n",
    "# ## expdict_cau, expdesc_cau = load_processed_logs_pickle( wdirg, maxjobid_cau, minjobid_cau )\n",
    "# ## expdict_cau2, expdesc_cau2 = load_processed_logs_pickle( wdirg, maxjobid_cau, minjobid_cau )\n",
    "# expdict_cau.update(expdict_cau2)\n",
    "# expdesc_cau.update(expdesc_cau2)\n",
    "# print expdesc_cau\n",
    "# minjobid_cau=1725\n",
    "# maxjobid_cau=1744\n",
    "# expdict_collect_cau, expdesc_collect_cau = load_logs_process_save( wdirg, maxjobid_cau, minjobid_cau )\n",
    "\n",
    "save_data_graz = 1\n",
    "save_data_cau = 1\n",
    "load_data_graz = 0\n",
    "load_data_cau = 0\n",
    "#### Save processed results and experments summaries\n",
    "wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/graz_testbed\"\n",
    "if save_data_graz:\n",
    "  saveObject(txpowerdata_graz_ntx, os.path.join(wdirg, \"txpowerdata_graz_ntx.pickle\"))\n",
    "  saveObject(expdesc_graz, os.path.join(wdirg, \"expdesc_graz.pickle\"))\n",
    "  saveObject(expdict_graz, os.path.join(wdirg, \"expdict_graz.pickle\"))\n",
    "  saveObject(expsummary_all_graz, os.path.join(wdirg, \"expsummary_all_graz.pickle\"))\n",
    "elif load_data_graz:\n",
    "  txpowerdata_graz_ntx = loadObject(os.path.join(wdirg, \"txpowerdata_graz_ntx.pickle\"))\n",
    "  expdesc_graz = loadObject(os.path.join(wdirg, \"expdesc_graz.pickle\"))\n",
    "  expdict_graz = loadObject(os.path.join(wdirg, \"expdict_graz.pickle\"))\n",
    "  expsummary_all_graz = loadObject(os.path.join(wdirg, \"expsummary_all_graz.pickle\"))\n",
    "\n",
    "wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/cau_testbed\"\n",
    "if save_data_cau:\n",
    "  saveObject(txpowerdata_cau_ntx, os.path.join(wdirg, \"txpowerdata_cau_ntx.pickle\"))\n",
    "  saveObject(expdesc_cau, os.path.join(wdirg, \"expdesc_cau.pickle\"))\n",
    "  saveObject(expdict_cau, os.path.join(wdirg, \"expdict_cau.pickle\"))\n",
    "  saveObject(expsummary_all_cau, os.path.join(wdirg, \"expsummary_all_cau.pickle\"))\n",
    "elif load_data_cau:\n",
    "  txpowerdata_cau_ntx = loadObject(os.path.join(wdirg, \"txpowerdata_cau_ntx.pickle\"))\n",
    "  expdesc_cau = loadObject(os.path.join(wdirg, \"expdesc_cau.pickle\"))\n",
    "  expdict_cau = loadObject(os.path.join(wdirg, \"expdict_cau.pickle\"))\n",
    "  expsummary_all_cau = loadObject(os.path.join(wdirg, \"expsummary_all_cau.pickle\"))\n",
    "\n",
    "\n",
    "\n",
    "# saveObject(expdesc_cau, os.path.join(wdirg, \"expdesc_cau_test.pickle\"))\n",
    "# saveObjectMP(expdict_cau, os.path.join(wdirg, \"expdict_cau.mp\"))\n",
    "# expdesc_cau_test = loadObject(os.path.join(wdirg, \"expdesc_cau_test.pickle\"))\n",
    "# expdict_cau_MP = loadObjectMP(os.path.join(wdirg, \"expdesc_cau_test.mp\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nchdata_cau_ntx[4][5][\"x\"]\n",
    "\n",
    "remove_failed_exp = 0\n",
    "\n",
    "if remove_failed_exp:\n",
    "  if not(\"failedexp\" in locals() or \"failedexp\" in globals()):\n",
    "  #   failedexp=dict()\n",
    "    wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/cau_testbed\"\n",
    "    failedexp = loadObject(os.path.join(wdirg, \"failedexp.pickle\"))\n",
    "\n",
    "  for exp in expdesc_cau.keys(): #range(startexpcau, 1724,1):\n",
    "    if exp < startexpcau:\n",
    "      continue\n",
    "  # print expsummary_all_cau[exp]\n",
    "  # print expdesc_cau[exp], expdict_cau\n",
    "    nologsnodes=[ (i, expdict_cau[exp][i][\"PER\"] ) for i in expdict_cau[exp].keys() if  (expdict_cau[exp][i][\"PER\"] < 0 and i!=1) or expdict_cau[exp][i][\"PER\"] > 0.9]\n",
    "    if len(nologsnodes) > 0:\n",
    "      print exp_desc_to_string(exp, expdesc_cau), len(nologsnodes)\n",
    "      failedexp[exp] = dict()\n",
    "      failedexp[exp][\"name\"] = exp_desc_to_string(exp, expdesc_cau)\n",
    "      failedexp[exp][\"failed\"] = nologsnodes\n",
    "\n",
    "      try:\n",
    "        if expdesc_cau.has_key(exp):\n",
    "          failedexp[exp][\"desc\"] = expdesc_cau[exp]\n",
    "          del expdesc_cau[exp] \n",
    "        if expdict_cau.has_key(exp):\n",
    "          failedexp[exp][\"dict\"] = expdict_cau[exp]\n",
    "          del expdict_cau[exp] \n",
    "        if expsummary_all_cau.has_key(exp):\n",
    "          failedexp[exp][\"summary\"] = expsummary_all_cau[exp]\n",
    "          del expsummary_all_cau[exp]\n",
    "      except e as Exception:\n",
    "        print e\n",
    "# wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/cau_testbed\"\n",
    "# saveObject(failedexp, os.path.join(wdirg, \"failedexp.pickle\"))\n",
    "del failedexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## aggregate experiments \n",
    "[ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0] = [0, 3, 0, 0, 0, 38, 3, 0, 8, 0]\n",
    "\n",
    "blemodes = ble_mode_str_dict.keys()\n",
    "blemodes.sort()\n",
    "startexpgraz=23245\n",
    "startexpcau=1148\n",
    "ntxx=[2, 3, 4, 8]\n",
    "txpowerx=[-8, -4, 0, 4, 8]\n",
    "do_txpower_cau=0\n",
    "do_txpower_graz=0\n",
    "do_nch_cau = 0\n",
    "do_nch_graz = 0\n",
    "do_packet_size_cau = 0\n",
    "do_packet_size_graz = 0\n",
    "do_ntx_cau = 1\n",
    "do_ntx_graz = 1\n",
    "\n",
    "if do_ntx_cau:\n",
    "  # fixntx\n",
    "  expdesc_cau_fixed_ntx = copy.deepcopy(expdesc_cau)\n",
    "  for exp in expdesc_cau_fixed_ntx.keys():\n",
    "    expdesc_cau_fixed_ntx[exp][expdesc_usage.ntx] = expdesc_cau[exp][expdesc_usage.ntx] - 1\n",
    "  param_index = expdesc_usage.ntx\n",
    "  testbed0=\"CAU\"\n",
    "  expsummary_ntx_cau=dict()\n",
    "  ntxdata_cau_txpower=dict()\n",
    "  for txpower0 in txpowerx:\n",
    "    param0 = [ ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0, testbed0 ]\n",
    "    ntxdata_cau_txpowerx, expsummary_ntx_cau_txpowerx =extract_exp_summary_parameterized(expdesc_cau_fixed_ntx, expdict_cau, startexpcau, blemodes, param0, param_index)\n",
    "    expsummary_ntx_cau.update(expsummary_ntx_cau_txpowerx)\n",
    "    ntxdata_cau_txpower[txpower0]=ntxdata_cau_txpowerx.copy()\n",
    "\n",
    "if do_ntx_graz:\n",
    "  param_index = expdesc_usage.ntx\n",
    "    # fixntx\n",
    "  expdesc_graz_fixed_ntx = copy.deepcopy(expdesc_graz)\n",
    "  for exp in expdesc_graz_fixed_ntx.keys():\n",
    "    expdesc_graz_fixed_ntx[exp][expdesc_usage.ntx] = expdesc_graz[exp][expdesc_usage.ntx] - 1\n",
    "  testbed0=\"GRAZ\"\n",
    "  expsummary_ntx_graz=dict()\n",
    "  ntxdata_graz_txpower=dict()\n",
    "  for txpower0 in txpowerx:\n",
    "    param0 = [ ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0, testbed0 ]\n",
    "    ntxdata_graz_txpowerx, expsummary_ntx_graz_txpowerx =extract_exp_summary_parameterized(expdesc_graz_fixed_ntx, expdict_graz, startexpgraz, blemodes, param0, param_index)\n",
    "    expsummary_ntx_graz.update(expsummary_ntx_graz_txpowerx)\n",
    "    ntxdata_graz_txpower[txpower0]=ntxdata_graz_txpowerx.copy()\n",
    "    \n",
    "if do_packet_size_graz:\n",
    "  param_index = expdesc_usage.packet_size\n",
    "  testbed0=\"GRAZ\"\n",
    "  expsummary_packet_size_graz=dict()\n",
    "  packet_sizedata_graz_ntx=dict()\n",
    "  for ntx0 in ntxx:\n",
    "    param0 = [ ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0, testbed0 ]\n",
    "    packet_sizedata_graz_ntxx, expsummary_packet_size_graz_ntxx =extract_exp_summary_parameterized(expdesc_graz, expdict_graz, startexpgraz, blemodes, param0, param_index)\n",
    "    expsummary_packet_size_graz.update(expsummary_packet_size_graz_ntxx)\n",
    "    packet_sizedata_graz_ntx[ntx0]=packet_sizedata_graz_ntxx.copy()\n",
    "    \n",
    "if do_packet_size_cau:\n",
    "  param_index = expdesc_usage.packet_size\n",
    "  testbed0=\"CAU\"\n",
    "  expsummary_packet_size_cau=dict()\n",
    "  packet_sizedata_cau_ntx=dict()\n",
    "  for ntx0 in ntxx:\n",
    "    param0 = [ ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0, testbed0 ]\n",
    "    packet_sizedata_cau_ntxx, expsummary_packet_size_cau_ntxx =extract_exp_summary_parameterized(expdesc_cau, expdict_cau, startexpcau, blemodes, param0, param_index)\n",
    "    expsummary_packet_size_cau.update(expsummary_packet_size_cau_ntxx)\n",
    "    packet_sizedata_cau_ntx[ntx0]=packet_sizedata_cau_ntxx.copy()\n",
    "\n",
    "if do_nch_graz:\n",
    "  param_index = expdesc_usage.nch\n",
    "  testbed0=\"GRAZ\"\n",
    "  expsummary_nch_graz=dict()\n",
    "  nchdata_graz_ntx=dict()\n",
    "  for ntx0 in ntxx:\n",
    "    param0 = [ ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0, testbed0 ]\n",
    "    nchdata_graz_ntxx, expsummary_nch_graz_ntxx = extract_exp_summary_parameterized(expdesc_graz, expdict_graz, startexpgraz, blemodes, param0, param_index)\n",
    "    expsummary_nch_graz.update(expsummary_nch_graz_ntxx)\n",
    "    nchdata_graz_ntx[ntx0]=nchdata_graz_ntxx.copy()\n",
    "    \n",
    "if do_nch_cau:\n",
    "  param_index = expdesc_usage.nch\n",
    "  testbed0=\"CAU\"\n",
    "  expsummary_nch_cau=dict()\n",
    "  nchdata_cau_ntx=dict()\n",
    "  for ntx0 in ntxx:\n",
    "    param0 = [ ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0, testbed0 ]\n",
    "    nchdata_cau_ntxx, expsummary_nch_cau_ntxx = extract_exp_summary_parameterized(expdesc_cau, expdict_cau, startexpcau, blemodes, param0, param_index)\n",
    "    expsummary_nch_cau.update(expsummary_nch_cau_ntxx)\n",
    "    nchdata_cau_ntx[ntx0]=nchdata_cau_ntxx.copy()\n",
    "  \n",
    "if do_txpower_cau:\n",
    "  param_index = expdesc_usage.txpower\n",
    "  testbed0=\"CAU\"\n",
    "  expsummary_cau=dict()\n",
    "  txpowerdata_cau_ntx=dict()\n",
    "  for ntx0 in ntxx:\n",
    "    param0 = [ ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0, testbed0 ]\n",
    "    txpowerdata_cau_ntxx, expsummary_cau_ntxx = extract_exp_summary_parameterized(expdesc_cau, expdict_cau, startexpcau, blemodes, param0, param_index)\n",
    "    expsummary_cau.update(expsummary_cau_ntxx)\n",
    "    txpowerdata_cau_ntx[ntx0]=txpowerdata_cau_ntxx.copy()\n",
    "\n",
    "if do_txpower_graz:\n",
    "  param_index = expdesc_usage.txpower\n",
    "  testbed0=\"GRAZ\"\n",
    "  expsummary_graz=dict()\n",
    "  txpowerdata_graz_ntx=dict()\n",
    "  for ntx0 in ntxx:\n",
    "    param0 = [ ts0, ble_mode0, txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0, initiator0, testbed0 ]\n",
    "    txpowerdata_graz_ntxx, expsummary_graz_ntxx = extract_exp_summary_parameterized(expdesc_graz, expdict_graz, startexpgraz, blemodes, param0, param_index)\n",
    "    expsummary_graz.update(expsummary_graz_ntxx)\n",
    "    txpowerdata_graz_ntx[ntx0]=txpowerdata_graz_ntxx.copy()\n",
    "\n",
    "expsummary_all_cau=dict()\n",
    "expsummary_all_cau.update(expsummary_ntx_cau)\n",
    "expsummary_all_cau.update(expsummary_packet_size_cau)\n",
    "expsummary_all_cau.update(expsummary_nch_cau)\n",
    "expsummary_all_cau.update(expsummary_cau)\n",
    "\n",
    "expsummary_all_graz=dict()\n",
    "expsummary_all_graz.update(expsummary_ntx_graz)\n",
    "expsummary_all_graz.update(expsummary_packet_size_graz)\n",
    "expsummary_all_graz.update(expsummary_nch_graz)\n",
    "expsummary_all_graz.update(expsummary_graz)\n",
    "\n",
    "# startexphome=40\n",
    "# txpowerdata_home, expsummary_home = extract_exp_summary(expdesc_home, expdict_home, startexphome, blemodes, [txoffset0, capture0, packet_size0, nch0, och0, ntx0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed] = expdesc[expid]\n",
    "# exptext_graz = [ \"%d: mode %d @%ddb, %d ntx, PER %0.3f%% \" % (expid, expdesc_graz[expid][1], expdesc_graz[expid][2], expdesc_graz[expid][8], expsummary_graz_ntx4[expid][0]*100) for expid in expsummary_graz_ntx4.keys() ]\n",
    "# print exptext_graz\n",
    "# exptext_ntx4_cau = [ \"%d: mode %d @%ddb, %d ntx, PER %0.3f%% \" % (expid, expdesc_cau[expid][1], expdesc_cau[expid][2], expdesc_cau[expid][8], expsummary_cau_ntx4[expid][0]*100) for expid in expsummary_cau_ntx4.keys() ]\n",
    "# print exptext_ntx4_cau\n",
    "\n",
    "# wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/graz_testbed\"\n",
    "# minjobid_graz=27424\n",
    "# maxjobid_graz=27425\n",
    "# load_logs_process_save_graz( wdirg, grazq, maxjobid_graz, minjobid_graz )\n",
    "# expdict_g, expdesc_g = load_processed_logs_pickle_graz( wdirg, grazq, maxjobid_graz, minjobid_graz )\n",
    "# print [ (i, expdict_g[27424][i][\"PER\"]) for i in expdict_g[27424].keys() ]\n",
    "# print [ (i, expdict_g[1207][i][\"PER\"]) for i in expdict_cau[1207].keys() ]\n",
    "# print \"[avg_per, stddev_per, avg_hopcount, stddev_hopcount, avg_onslots, stddev_onslots ]\", expsummary_graz[27424]\n",
    "# high_per_expsummary_cau = high_per_expdesc_cau = high_per_expdict_cau = dict()\n",
    "# high_per_exp_graz = [ (exp, expsummary_graz[exp][expsummary_usage.avg_per], expdesc_graz[exp]) for exp in expsummary_graz.keys() if expsummary_graz[exp][expsummary_usage.avg_per] > 0.1]\n",
    "# print high_per_exp_graz\n",
    "# for exp in [e[0] for e in high_per_exp_graz]:\n",
    "#   print exp, expsummary_graz[exp][expsummary_usage.avg_per], '\\n', [ (i, expdict_graz[exp][i][\"PER\"] ) for i in expdict_graz[exp].keys() if  expdict_graz[exp][i][\"PER\"] > 0.9 ]#expsummary_graz[exp][expsummary_usage.avg_per]]\n",
    "\n",
    "### delete graz experiments with txpower -2, as it does not cover the network:\n",
    "# for exp in expsummary_graz.keys():\n",
    "#   if expdesc_graz[exp][expdesc_usage.txpower] == -2:\n",
    "#     print exp, expdesc_graz[exp]\n",
    "#     del expdesc_graz[exp], expdict_graz[exp], expsummary_graz[exp]\n",
    "\n",
    "high_per_exp = [ (exp, expsummary_all_cau[exp][expsummary_usage.avg_per], expdesc_cau[exp]) for exp in expsummary_all_cau.keys() if expsummary_all_cau[exp][expsummary_usage.avg_per] > 0.8]\n",
    "# print high_per_exp\n",
    "for exp in [e[0] for e in high_per_exp]:\n",
    "  per=expsummary_all_cau[exp][expsummary_usage.avg_per]\n",
    "  print exp_desc_to_string(exp, expdesc_cau) + \"PER: {:.3}\".format(per)\n",
    "#   print exp, expsummary_all_cau[exp][expsummary_usage.avg_per]\n",
    "  print [ (i, expdict_cau[exp][i][\"PER\"] ) for i in expdict_cau[exp].keys() if  expdict_cau[exp][i][\"PER\"] > expsummary_all_cau[exp][expsummary_usage.avg_per]]\n",
    "\n",
    "##### Delete experiments that have unconnected nodes only: PER == 1 for these nodes -- check the logs and conform this was the join bug, before deleting!\n",
    "##   high_per_expsummary_cau[exp] = copy.copy(expsummary_cau[exp])\n",
    "##   high_per_expdesc_cau[exp] = copy.copy(expdesc_cau[exp])\n",
    "##   high_per_expdict_cau[exp] = copy.copy(expdict_cau[exp])\n",
    "###   del expdesc_cau[exp], expdict_cau[exp], expsummary_cau[exp]\n",
    "### delete failed experiment:\n",
    "### 1365: 2020_1_31_9_46_52 ble_mode_5_txpower_0_txoffset_0_capt_0_packet_size_38_nch_40_och_0_ntx_4_i_0_testbed_CAU PER: 0.158\n",
    "### [(9, 1), (10, 1), (18, 1)]\n",
    "# exp = 1365\n",
    "# del expdesc_cau[exp], expdict_cau[exp], expsummary_all_cau[exp]\n",
    "\n",
    "# for exp in expdesc_cau.keys():\n",
    "#   pp=[exp]+expdesc_cau[exp][expdesc_usage.ts]+expdesc_cau[exp][1:]+[expsummary_all_cau[exp][expsummary_usage.avg_per]]\n",
    "#   print expname_fmt.format(*pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting: /Users/beshr/work/blueflood/examples/nrf-glossy/cau_testbed/evaluate_packet_size_plot_cautestbed_ntx_4_exp_1148_1724.pdf\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 192x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### note that the actual number of transmissions is ntx - 1!!! The plot labels are fixed accordingly\n",
    "def plot_summary_testbed_ntx(testbed, parameters, startexp, endexp, x_lbl, paramplotname, data_variable_name, paramplotname2=\"ntx\", paramplotvalue2=None, legend_idx=2, doplots=[1,1,1], legendloc='lower center'):\n",
    "  [txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0] = parameters\n",
    "  if paramplotvalue2 is None:\n",
    "    paramplotvalue2=ntx0\n",
    "  testbed = str(testbed).lower()\n",
    "  wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/%s_testbed\" %(testbed)\n",
    "  plotfilename=\"evaluate_%s_plot_%stestbed_%s_%d_exp_%d_%d.pdf\" % (paramplotname, testbed, paramplotname2, paramplotvalue2, startexp, endexp)\n",
    "  file_name = os.path.join(wdirg, plotfilename)\n",
    "  print \"plotting: \" + file_name\n",
    "  plot_summary_plots(globals()[data_variable_name % (testbed)][paramplotvalue2], blemodes, file_name, x_lbl, legend_idx, doplots, legendloc)\n",
    "\n",
    "plot_x_txpower = 0\n",
    "plot_x_nch = 0\n",
    "plot_x_packet_size = 1\n",
    "plot_x_ntx = 0\n",
    "plotcau = 1\n",
    "plotgraz = 0\n",
    "[txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0] = [0, 0, 0, 38, 3, 0, 8]\n",
    "\n",
    "if plot_x_ntx:\n",
    "  for txpower0 in txpowerx: \n",
    "    params0 = [txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0]\n",
    "    x_lbl=\"$N_{TX}$, with: $TX_{Power}=%d$ [dB], $N_{Channels}=%d$\" %(txpower0, nch0)\n",
    "    if plotcau:\n",
    "      plot_summary_testbed_ntx(\"cau\", params0, startexpcau, maxjobid_cau, x_lbl, \"ntx\", \"ntxdata_%s_txpower\", \"txpower\", txpower0, legend_idx=0, doplots=[1, 0, 0], legendloc='upper center')\n",
    "    if plotgraz:\n",
    "      plot_summary_testbed_ntx(\"graz\", params0, startexpgraz, maxjobid_graz, x_lbl, \"ntx\", \"ntxdata_%s_txpower\", \"txpower\", txpower0, legend_idx=0, doplots=[1, 0, 0], legendloc='upper center')\n",
    "    \n",
    "if plot_x_txpower:\n",
    "  for ntx0 in ntxx:\n",
    "    params0 = [txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0]\n",
    "    x_lbl=\"$TX_{Power}$ [dB], with: $N_{Channels}=%d$, $N_{TX}=%d$\" %(nch0, ntx0-1)\n",
    "    if plotcau:\n",
    "      plot_summary_testbed_ntx(\"cau\", params0, startexpcau, maxjobid_cau, x_lbl, \"txpower\", \"txpowerdata_%s_ntx\", \"ntx\", ntx0)\n",
    "    if plotgraz:\n",
    "      plot_summary_testbed_ntx(\"graz\", params0, startexpgraz, maxjobid_graz, x_lbl, \"txpower\", \"txpowerdata_%s_ntx\", \"ntx\", ntx0)\n",
    "\n",
    "if plot_x_nch:\n",
    "  for ntx0 in [4]:\n",
    "    params0 = [txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0]\n",
    "    x_lbl=\"$N_{Channels}$, with: $TX_{Power}=%d$ [dB], $N_{TX}=%d$\" %(txpower0, ntx0-1)\n",
    "    if plotcau:\n",
    "      plot_summary_testbed_ntx(\"cau\", params0, startexpcau, maxjobid_cau, x_lbl, \"nch\", \"nchdata_%s_ntx\", \"ntx\", ntx0)\n",
    "    if plotgraz:\n",
    "      plot_summary_testbed_ntx(\"graz\", params0, startexpgraz, maxjobid_graz, x_lbl, \"nch\", \"nchdata_%s_ntx\", \"ntx\", ntx0)\n",
    "\n",
    "if plot_x_packet_size:\n",
    "  for ntx0 in [4]:\n",
    "    params0 = [txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0]\n",
    "    x_lbl=\"$Packet_{Size}$, with: $TX_{Power}=%d$ [dB], $N_{TX}=%d$\" %(txpower0, ntx0-1)\n",
    "    if plotcau:\n",
    "      plot_summary_testbed_ntx(\"cau\", params0, startexpcau, maxjobid_cau, x_lbl, \"packet_size\", \"packet_sizedata_%s_ntx\", \"ntx\", ntx0, legend_idx=0, doplots=[1, 0, 0], legendloc='upper center')\n",
    "    if plotgraz:\n",
    "      plot_summary_testbed_ntx(\"graz\", params0, startexpgraz, maxjobid_graz, x_lbl, \"packet_size\", \"packet_sizedata_%s_ntx\", \"ntx\", ntx0, legend_idx=0, doplots=[1, 0, 0], legendloc='upper center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary_boxplots(txpowerdata, blemodes, file_name):\n",
    "  capsize=3\n",
    "  markersize=3\n",
    "  linewidth=1.5\n",
    "  linestyle=linestyles[0]\n",
    "  norm = matplotlib.colors.Normalize(vmin=0, vmax=len(blemodes)+1)\n",
    "\n",
    "  #fig = plt.figure(figsize=(4, 6))  #width, height\n",
    "  fig, axx = plt.subplots(ncols=3, sharey=False, sharex=True, figsize=(12,3))\n",
    "  #axmain = fig.add_subplot(111,frameon=False)\n",
    "  # Turn off axis lines and ticks of the big subplot\n",
    "  #axmain.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
    "  #axx[1].set_ylim(80, 100.5)\n",
    "\n",
    "  for counter, ble_mode in enumerate(blemodes):\n",
    "    color=plt.get_cmap('Accent')(norm(counter))\n",
    "    marker=markers[counter]\n",
    "  #   if res != 0:\n",
    "  #     txp_per_err = list(np.asarray(txpowerdata[ble_mode][\"perstd\"]) + res)\n",
    "  #     txp_per =  list(np.asarray(txpowerdata[ble_mode][\"per\"]) + res)\n",
    "  #   #   yerr = np.log10(txp_per_err)\n",
    "  #   #   y=np.log10(txp_per)\n",
    "  #     yerr = txp_per_err\n",
    "  #     y=txp_per\n",
    "  #   else:\n",
    "      #shallow copy\n",
    "    yerr=copy.copy(txpowerdata[ble_mode][\"perstd\"])\n",
    "    y=copy.copy(txpowerdata[ble_mode][\"per\"])\n",
    "    yerr1=copy.copy(txpowerdata[ble_mode][\"hopcountstd\"])\n",
    "    y1=copy.copy(txpowerdata[ble_mode][\"hopcount\"])\n",
    "    yerr2=copy.copy(txpowerdata[ble_mode][\"onslotsstd\"])\n",
    "    y2=copy.copy(txpowerdata[ble_mode][\"onslots\"])\n",
    "    axx[0].errorbar(txpowerdata[ble_mode][\"x\"], y, yerr=yerr, linestyle=linestyle, color = color, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "    #axx[0].boxplot(y, positions=txpowerdata[ble_mode][\"x\"], notch=True)\n",
    "    axx[1].errorbar(txpowerdata[ble_mode][\"x\"], y1, yerr=yerr1, label=ble_mode_str_dict[ble_mode], linestyle=linestyle, color = color, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "    #axx[1].boxplot(y1, positions=txpowerdata[ble_mode][\"x\"], notch=True)\n",
    "    axx[2].errorbar(txpowerdata[ble_mode][\"x\"], y2, yerr=yerr2, linestyle=linestyle, color = color, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "    #axx[2].boxplot(y2, positions=txpowerdata[ble_mode][\"x\"], notch=True)\n",
    "\n",
    "    axx[0].set_yscale('symlog', linthreshy=0.00001)\n",
    "    axx[1].legend(loc=\"best\",  ncol=2)\n",
    "    \n",
    "  ylabels=[\"E2E PER\", \"Hopcount\", \"Active slots\"]\n",
    "  for i, ax in enumerate(axx):\n",
    "    ax.grid()\n",
    "    # axx.set_yscale('log')\n",
    "    #ax.set_xlim(min(txpowerdata[ble_mode][\"x\"])-0.2, max(txpowerdata[ble_mode][\"x\"])+0.2)\n",
    "  #   ax.set_xlabel('TX power [dB]')\n",
    "    ax.set_ylabel(ylabels[i])\n",
    "\n",
    "  x_lbl=\"$TX_{Power}$ [dB], with: $N_{Channels}=%d$, $N_{TX}=%d$\" %(nch0, ntx0-1)\n",
    "  fig.text(0.5, 0.00, x_lbl, ha='center')\n",
    "  fig.tight_layout()\n",
    "  # plt.subplots_adjust(left=0, top=2)\n",
    "  plt.savefig(file_name, bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startexp=23245\n",
    "wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/graz_testbed\"\n",
    "plotfilename=\"evaluate_txpower_boxplot_graztestbed-%d.pdf\" % startexp\n",
    "file_name = os.path.join(wdirg, plotfilename)\n",
    "print \"plotting: \" + file_name\n",
    "plot_summary_boxplots(txpowerdata_graz, blemodes, file_name)\n",
    "\n",
    "startexp=1\n",
    "wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/cau_testbed\"\n",
    "plotfilename=\"evaluate_txpower_boxplot_cautestbed-%d.pdf\" % startexp\n",
    "file_name = os.path.join(wdirg, plotfilename)\n",
    "print \"plotting: \" + file_name\n",
    "plot_summary_boxplots(txpowerdata_cau, blemodes, file_name)\n",
    "\n",
    "wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/home_testbed\"\n",
    "plotfilename=\"evaluate_txpower_boxplot_hometestbed-%d.pdf\" % startexp\n",
    "file_name = os.path.join(wdirg, plotfilename)\n",
    "print \"plotting: \" + file_name\n",
    "plot_summary_boxplots(txpowerdata_home, blemodes, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse experiment and save results\n",
    "wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/graz_testbed\"\n",
    "exp_path = os.path.join(wdirg, \"logs_23263\")\n",
    "nodes = load_testbed_node_log_files(exp_path);\n",
    "saveObject(nodes, os.path.join(exp_path, \"nodes.pickle\"))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load parsed results\n",
    "expid=23252\n",
    "wdirg=\"/Users/beshr/work/blueflood/examples/nrf-glossy/graz_testbed\"\n",
    "exp_path = os.path.join(wdirg, \"logs_%d\" % (expid))\n",
    "nodes = loadObject(os.path.join(exp_path, \"nodes.pickle\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y1 is plotted on log scale axis\n",
    "def plot_exp(x, xticks, x_lbl, lbl, y1, yerr1, y2, yerr2, y3, yerr3, ylabels, expn, wdirg, color, fig=None, axx=None, marker='*'):\n",
    "  capsize=3\n",
    "  markersize=3\n",
    "  linewidth=1.5\n",
    "  linestyle=linestyles[0]\n",
    "  #color='b'\n",
    "\n",
    "  #fig = plt.figure(figsize=(4, 6))  #width, height\n",
    "  if fig is None or axx is None:\n",
    "    fig, axx = plt.subplots(ncols=3, sharey=False, sharex=True, figsize=(12,3))\n",
    "#   plotfilename=\"plot_graztestbed_exp%d.pdf\" % expn\n",
    "#   file_name = os.path.join(wdirg, plotfilename)\n",
    "  #print \"plotting: \" + x_lbl + \", \" + lbl\n",
    "  axx[0].errorbar(x, y1, yerr=yerr1, linestyle=linestyle, color = color, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "  axx[1].errorbar(x, y2, yerr=yerr2, label=lbl, linestyle=linestyle, color = color, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "  axx[2].errorbar(x, y3, yerr=yerr3, linestyle=linestyle, color = color, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "  #log scale, but make a linear region around zero to avoid problems with zero, as log(0) is nan\n",
    "  axx[0].set_yscale('symlog', linthreshy=0.00001)\n",
    "  axx[1].legend(loc=\"best\",  ncol=1)\n",
    "\n",
    "  for i, ax in enumerate(axx):\n",
    "    ax.grid()\n",
    "    #ax.set_xlim(min(txpowerdata[ble_mode][\"x\"])-0.2, max(txpowerdata[ble_mode][\"x\"])+0.2)\n",
    "    ax.set_ylabel(ylabels[i])\n",
    "    ax.set_xticks(x, minor=True)\n",
    "    ax.set_xticklabels(xticks, minor=True)\n",
    "    #ax.set_xticklabels(xticks[0:10:len(xticks)], minor=False)\n",
    "\n",
    "    ax.minorticks_off()\n",
    "\n",
    "  if x_lbl is not None:\n",
    "    fig.text(0.5, 0.00, x_lbl, ha='center')\n",
    "  fig.tight_layout()\n",
    "  #plt.savefig(file_name, bbox_inches='tight')\n",
    "  #plt.show()\n",
    "  return fig, axx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for one tx power\n",
    "def plot_micro_view_for_txpowers(expdict, expdesc, startexp, blemodes, txpowerset, params, plotnametemplate, wdirg):\n",
    "  [txoffset0, capture0, packet_size0, nch0, och0, ntx0]=params\n",
    "  norm = matplotlib.colors.Normalize(vmin=0, vmax=len(blemodes)+1)\n",
    "  ncols=4\n",
    "  for txpower0 in txpowerset:\n",
    "    fig, axx = plt.subplots(ncols=ncols, sharey=False, sharex=False, figsize=(4*ncols,3))\n",
    "    x_lbl_written = False\n",
    "    for expid in expdesc.keys():\n",
    "      if expid >= startexp:\n",
    "        [ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed] = expdesc[expid]\n",
    "        if [txpower, txoffset, capture, packet_size, nch, och, ntx] == [txpower0, txoffset0, capture0, packet_size0, nch0, och0, ntx0]:\n",
    "          nodes=expdict[expid].copy()\n",
    "          nodeids=list(nodes.keys())\n",
    "          nodeids.sort()\n",
    "          x = range(0, len(nodeids), 1)\n",
    "\n",
    "          y1 = [nodes[i][\"PER\"] if nodes[i][\"PER\"] != -1 else 0 for i in nodeids ]\n",
    "          #yerr1 = np.std(y1)\n",
    "          yerr1 = None   \n",
    "\n",
    "#           syncslots = [list(np.asarray(nodes[i][\"sync\"].values()))]\n",
    "          syncslots = [nodes[i][\"all\"].values() for i in nodeids]\n",
    "          syncslots = [[ d[1] for d in row if not d[0] ] for row in syncslots ]\n",
    "##         print syncslots\n",
    "          syncslots_flat = list(itertools.chain(*syncslots))\n",
    "          y2 = [nodes[i][\"hopcount\"][2] if nodes[i][\"hopcount\"][2] > -1 else 0 for i in nodeids]\n",
    "          yerr2 = [nodes[i][\"hopcount\"][3] if nodes[i][\"hopcount\"][2] > -1 else 0 for i in nodeids]\n",
    "          #print syncslots\n",
    "#           y2 = np.mean(syncslots ,axis=1)\n",
    "#           y2 = [np.mean(s) if len(s)>0 else 0 for s in syncslots]\n",
    "#           yerr2 = [np.std(s) if len(s)>0 else 0 for s in syncslots]\n",
    "\n",
    "#           y3 = [np.mean(nodes[i][\"tot\"].values()) for i in nodeids]\n",
    "#           yerr3 = [np.std(nodes[i][\"tot\"].values()) for i in nodeids]\n",
    "          y3 = [nodes[i][\"totslots\"][2] if nodes[i][\"totslots\"][2] > -1 else 0 for i in nodeids]\n",
    "          yerr3 = [nodes[i][\"totslots\"][3] if nodes[i][\"totslots\"][2] > -1 else 0 for i in nodeids]\n",
    "    \n",
    "          color=plt.get_cmap('Accent')(norm(blemodes.index(ble_mode)))\n",
    "          lbl = ble_mode_str_dict[ble_mode]\n",
    "          #x_lbl0=\"Experiment %d, Node IDs\" % expid\n",
    "          x_lbl0=\"Node index. Parameters: $TX_{Power}$=%d dB, $N_{Channels}=%d$, $N_{TX}=%d$\" %(txpower0, nch0, ntx0-1)\n",
    "          if not x_lbl_written:\n",
    "            x_lbl = x_lbl0\n",
    "            x_lbl_written = True\n",
    "          else:\n",
    "            x_lbl=None\n",
    "          ylabels=[\"E2E PER\", \"Hopcount\", \"Active slots\", \"Sync slot Histogram\", \"Sync slot CDF\"]\n",
    "          print \"plotting: \" + x_lbl0 + \", \" + lbl\n",
    "          plot_exp(x, nodeids, x_lbl, lbl, y1, yerr1, y2, yerr2, y3, yerr3, ylabels, expid, wdirg, color, marker=markers[blemodes.index(ble_mode)], fig=fig, axx=axx)\n",
    "\n",
    "          n_bins=int(np.max(syncslots_flat))\n",
    "          #print syncslots\n",
    "          linewidth=1.5\n",
    "          n, bins, patches = axx[3].hist(syncslots_flat, n_bins, density=True, histtype='step',cumulative=True, color=color, linewidth=linewidth)\n",
    "          axx[3].set_xticks(bins, minor=True)\n",
    "          axx[3].set_xticklabels(bins, minor=True)\n",
    "          axx[3].minorticks_off()\n",
    "          axx[3].grid()\n",
    "          axx[3].grid()\n",
    "  #         bin_edges, cdf, hist = do_cdf(chain)\n",
    "  #         axx[4].errorbar(bin_edges, cdf, color=color, linestyle=linestyle, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "  #         axx[4].set_xticks(bin_edges, minor=True)\n",
    "  #         axx[4].set_xticklabels(bin_edges, minor=True)\n",
    "\n",
    "    plotfilename= plotnametemplate % txpower0\n",
    "    file_name = os.path.join(wdirg, plotfilename)\n",
    "    plt.savefig(file_name, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for one rf mode\n",
    "def plot_micro_view_for_rfmodes(expdict, expdesc, startexp, blemodes, txpowerset, params, plotnametemplate, wdirg):\n",
    "  [txoffset0, capture0, packet_size0, nch0, och0, ntx0]=params\n",
    "  norm = matplotlib.colors.Normalize(vmin=min(txpowerset), vmax=max(txpowerset)+1)\n",
    "  ncols=4\n",
    "  ble_mode_name=0\n",
    "  for ble_mode0 in blemodes:\n",
    "    fig, axx = plt.subplots(ncols=ncols, sharey=False, sharex=False, figsize=(4*ncols,3))\n",
    "    x_lbl_written=False\n",
    "    for expid in expdesc.keys():\n",
    "      if expid >= startexp:\n",
    "        [ts, ble_mode, txpower, txoffset, capture, packet_size, nch, och, ntx, initiator, testbed] = expdesc[expid]\n",
    "        if (txpower in txpowerset) and ([ble_mode, txoffset, capture, packet_size, nch, och, ntx] == [ble_mode0, txoffset0, capture0, packet_size0, nch0, och0, ntx0]):\n",
    "          ble_mode_name=ble_mode\n",
    "          nodes=expdict[expid].copy()\n",
    "          nodeids=list(nodes.keys())\n",
    "          nodeids.sort()\n",
    "          x = range(0, len(nodeids), 1)\n",
    "\n",
    "          y1 = [nodes[i][\"PER\"] if nodes[i][\"PER\"] != -1 else 0 for i in nodeids ]\n",
    "          #yerr1 = np.std(y1)\n",
    "          yerr1 = None\n",
    "\n",
    "          syncslots = [list(nodes[i][\"all\"].values()) for i in nodeids]\n",
    "          syncslots = [[ d[1] for d in row if not d[0] ] for row in syncslots  ]\n",
    "          \n",
    "          syncslots_flat = list(itertools.chain(*syncslots))\n",
    "          y2 = [np.mean(s) if len(s)>0 else 0 for s in syncslots]\n",
    "          yerr2 = [np.std(s) if len(s)>0 else 0 for s in syncslots]\n",
    "#           print len(y2), len(x)\n",
    "#           print yerr2\n",
    "#           syncslots = [list(np.asarray(nodes[i][\"sync\"].values()) + 1) if not nodes[i][\"is_initiator\"] else list(nodes[i][\"sync\"].values()) for i in nodeids]\n",
    "#           syncslots_flat = list(itertools.chain(*syncslots))\n",
    "#           y2 = [np.mean(s) for s in syncslots]\n",
    "#           yerr2 = [np.std(s) for s in syncslots]\n",
    "\n",
    "          y3 = [np.mean(nodes[i][\"tot\"].values()) for i in nodeids]\n",
    "          yerr3 = [np.std(nodes[i][\"tot\"].values()) for i in nodeids]\n",
    "\n",
    "          color=plt.get_cmap('Accent')(norm(txpower))\n",
    "          lbl=\"$TX_{Power}$ %d dB\" %(txpower)\n",
    "          #x_lbl0=\"Experiment %d, Node IDs\" % expid\n",
    "          x_lbl0=\"Node index. Parameters: Mode: %s, $N_{Channels}=%d$, $N_{TX}=%d$\" %(ble_mode_str_dict[ble_mode], nch, ntx-1)\n",
    "          if not x_lbl_written:\n",
    "            x_lbl = x_lbl0\n",
    "            x_lbl_written = True\n",
    "          else:\n",
    "            x_lbl=None\n",
    "          ylabels=[\"E2E PER\", \"Hopcount\", \"Active slots\", \"Sync slot Histogram\", \"Sync slot CDF\"]\n",
    "          print \"plotting: \" + x_lbl0 + \", \" + lbl\n",
    "          plot_exp(x, nodeids, x_lbl, lbl, y1, yerr1, y2, yerr2, y3, yerr3, ylabels, expid, wdirg, color, marker=markers[0], fig=fig, axx=axx)\n",
    "\n",
    "          n_bins=int(np.max(syncslots_flat))\n",
    "          #print syncslots\n",
    "          linewidth=1.5\n",
    "          n, bins, patches = axx[3].hist(syncslots_flat, n_bins, density=True, histtype='step',cumulative=True, color=color, linewidth=linewidth)\n",
    "          axx[3].set_xticks(bins, minor=True)\n",
    "          axx[3].set_xticklabels(bins, minor=True)\n",
    "          axx[3].minorticks_off()\n",
    "          axx[3].grid()\n",
    "          axx[3].grid()\n",
    "  #         bin_edges, cdf, hist = do_cdf(chain)\n",
    "  #         axx[4].errorbar(bin_edges, cdf, color=color, linestyle=linestyle, marker=marker, markersize=markersize, capsize=capsize, elinewidth=linewidth, linewidth=linewidth)\n",
    "  #         axx[4].set_xticks(bin_edges, minor=True)\n",
    "  #         axx[4].set_xticklabels(bin_edges, minor=True)\n",
    "\n",
    "    plotfilename= plotnametemplate % ble_mode_str_dict[ble_mode_name]\n",
    "    file_name = os.path.join(wdirg, plotfilename)\n",
    "    plt.savefig(file_name, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startexp=23245\n",
    "blemodes = ble_mode_str_dict.keys()\n",
    "blemodes.sort()\n",
    "[txoffset0, capture0, packet_size0, nch0, och0, ntx0] = [0, 0, 38, 3, 0, 4]\n",
    "params=[txoffset0, capture0, packet_size0, nch0, och0, ntx0]\n",
    "txpowerset=[0, 2, 4, 8]\n",
    "plotnametemplate = \"plot_graztestbed_exp_txpower_%d.pdf\"\n",
    "plot_micro_view_for_txpowers(expdict_graz, expdesc_graz, startexp, blemodes, txpowerset, params, plotnametemplate, wdirg)\n",
    "\n",
    "plotnametemplate = \"plot_graztestbed_exp_rfmode_%s.pdf\"\n",
    "plot_micro_view_for_rfmodes(expdict_graz, expdesc_graz, startexp, blemodes, txpowerset, params, plotnametemplate, wdirg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blemodes = ble_mode_str_dict.keys()\n",
    "blemodes.sort()\n",
    "[txoffset0, capture0, packet_size0, nch0, och0, ntx0] = [0, 0, 38, 3, 0, 4]\n",
    "txpowerset=[0, 2, 4]\n",
    "params=[txoffset0, capture0, packet_size0, nch0, och0, ntx0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Do some stats on parsed results\n",
    "hopcounts = [d[\"hopcount\"] for d in list(nodes.values())]\n",
    "per = [d[\"PER\"] for d in list(nodes.values())]\n",
    "print ' ', np.average(hopcounts, axis=0), np.std(hopcounts, axis=0), np.percentile(hopcounts, 70, axis=0)\n",
    "print ' ',  100*np.average(per, axis=0), 100*np.std(per, axis=0), 100*np.min(per, axis=0), \\\n",
    "100*np.max(per, axis=0)\n",
    "# Absolute mean deviation \n",
    "avg_per=np.mean(per)\n",
    "stddev_per=np.std(per)\n",
    "print ' Avg PER, std dev, Absolute mean deviation', 100*avg_per, 100*stddev_per, 100*np.mean(np.absolute(per - avg_per)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cdf(series):\n",
    "  ### from https://blog.finxter.com/numpy-cumsum/\n",
    "  # s=Size of our data\n",
    "  series_size=len(series)\n",
    "  # Sort the data and set bins edges\n",
    "  sorted_series = np.sort(series)\n",
    "  bins = np.append(sorted_series, sorted_series[-1]+1)\n",
    "  # Use the histogram function to bin the data\n",
    "  hist1, bin_edges = np.histogram(series, bins = bins)\n",
    "  # Account for the possible float data\n",
    "  hist = hist1.astype(float)/series_size\n",
    "  # Find the cdf\n",
    "  cdf = np.cumsum(hist)\n",
    "  return bin_edges[1:], cdf, hist1\n",
    "\n",
    "def do_percentile(series):\n",
    "  p=list()\n",
    "  r=range(0,101,10)\n",
    "  for i in r:\n",
    "    p.append(np.percentile(series, i, axis=0))\n",
    "  return r, p\n",
    "\n",
    "# plot the cumulative histogram\n",
    "x=hopcounts[3]\n",
    "n_bins=int(np.max(x))\n",
    "print x, n_bins\n",
    "n, bins, patches = plt.hist(x, n_bins, density=True, histtype='step',cumulative=True, label='Empirical')\n",
    "plt.show()\n",
    "\n",
    "bin_edges, cdf, hist = do_cdf(hopcounts[3])\n",
    "r, p = do_percentile(hopcounts[3])\n",
    "# Plot the cdf\n",
    "plt.plot(bin_edges, hist)\n",
    "plt.show()\n",
    "# Plot the cdf\n",
    "plt.plot(bin_edges, cdf)\n",
    "plt.show()\n",
    "plt.plot(cdf, bin_edges)\n",
    "plt.show()\n",
    "plt.plot(r,p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lline in [\":A..--CC...\", \":B---CCC--.....\", \":-BBBBBBBB.....\", \":B--------.....\",\":A.......-BBBB.\"]:\n",
    "  lline=str(lline)\n",
    "  is_initiator=False; synced=-1; sync_slot=-1; tot=0\n",
    "  if len(lline) > 1: #and len(lline) <= Round.ROUND_LEN+1:\n",
    "#                 if(len(lline)<Round.ROUND_LEN):\n",
    "#                     lline = lline.rjust(Round.ROUND_LEN+ 1, \"A\")\n",
    "#                     lline=lline.replace(':','A') #replace \n",
    "    ch=lline[1]\n",
    "    #replace left dots with the letter, and remove the right dots!\n",
    "    lline=re.sub(r'\\.*$',r'',lline) #remove trailing dots\n",
    "    lline=lline.replace('.',ch) #replace left dots with the first letter\n",
    "    tx_status = lline[1:]  #remove \":\"                  \n",
    "    #print self.tx_status\n",
    "    synced = tx_status.find(\"-\") \n",
    "    sync_slot = 1 + synced if synced != -1 else -1  #first rx ok\n",
    "    is_initiator = tx_status[0] in ['B', '1', '2']\n",
    "    if is_initiator:\n",
    "      sync_slot = 0\n",
    "\n",
    "    tot=len(tx_status)\n",
    "    \n",
    "  print lline, is_initiator, sync_slot, tot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! open -a Preview /Users/beshr/work/chaos/examples/nrf-glossy/exp-logs/evaluate_*.pdf\n",
    "#wdir=\"/Users/beshr/work/blueflood/examples/nrf-glossy/cau_testbed\"\n",
    "! open -a Preview /Users/beshr/work/blueflood/examples/nrf-glossy/cau_testbed/*.pdf\n",
    "#! open -a Preview /Users/beshr/work/chaos/examples/nrf-glossy/exp-logs/evaluate_txpower_plot0.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[2,1,0]\n",
    "a=np.asarray(a)\n",
    "b=9\n",
    "c=list()\n",
    "c.append(b)\n",
    "c.append(b-1)\n",
    "c.append(b+1)\n",
    "print a, c\n",
    "idx=np.argsort(a)\n",
    "a.sort()\n",
    "c = np.asarray(c)\n",
    "c = c[idx]\n",
    "print a, c\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
